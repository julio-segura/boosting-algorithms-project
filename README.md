# Predicting diabetes
In the two previous projects we saw how we could use a decision tree and then a random forest to improve the prediction of diabetes. We have reached a point where we need to improve. Can boosting be the best alternative to optimize the results?

Boosting is a sequential composition of models (usually decision trees) in which the new model aims to correct the errors of the previous one. This view may be useful in this data set, since several of the assumptions studied in the module are met.

You can find the previous projects here: 
https://github.com/julio-segura/decision-tree-project
https://github.com/julio-segura/random-forest-project
